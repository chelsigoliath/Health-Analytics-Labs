{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2703aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  Year LocationAbbr LocationDesc                        Class  \\\n",
      "0      0  2011           AR     Arkansas             Control Variable   \n",
      "1      1  2011           AR     Arkansas  Insurance/Medicaid/Services   \n",
      "2      2  2011           AR     Arkansas  Insurance/Medicaid/Services   \n",
      "3      3  2011           AR     Arkansas  Insurance/Medicaid/Services   \n",
      "4      4  2011           AR     Arkansas  Insurance/Medicaid/Services   \n",
      "\n",
      "                    Topic                                           Question  \\\n",
      "0  Prenatal Care - Visits                      Indicator of no prenatal care   \n",
      "1                Medicaid  Indicator of whether mother received Medicaid ...   \n",
      "2                Medicaid  Indicator of whether mother received Medicaid ...   \n",
      "3                Medicaid  Indicator of whether mother received Medicaid ...   \n",
      "4                Medicaid  Indicator of whether mother received Medicaid ...   \n",
      "\n",
      "  DataSource        Response Data_Value_Unit  ...      Break_Out  \\\n",
      "0      PRAMS              NO               %  ...    Age 18 - 44   \n",
      "1      PRAMS             NaN               %  ...            NaN   \n",
      "2      PRAMS  NO (UNCHECKED)               %  ...  LBW (<=2500g)   \n",
      "3      PRAMS   YES (CHECKED)               %  ...  LBW (<=2500g)   \n",
      "4      PRAMS  NO (UNCHECKED)               %  ...   NBW (>2500g)   \n",
      "\n",
      "                   Break_Out_Category  \\\n",
      "0  Maternal Age - 18 to 44 years only   \n",
      "1                        Birth Weight   \n",
      "2                        Birth Weight   \n",
      "3                        Birth Weight   \n",
      "4                        Birth Weight   \n",
      "\n",
      "                               Geolocation ClassId  TopicId  QuestionId  \\\n",
      "0  (34.74865012400045, -92.27449074299966)    CLA1    TOP44      QUO171   \n",
      "1  (34.74865012400045, -92.27449074299966)   CLA10    TOP12       QUO25   \n",
      "2  (34.74865012400045, -92.27449074299966)   CLA10    TOP12       QUO25   \n",
      "3  (34.74865012400045, -92.27449074299966)   CLA10    TOP12       QUO25   \n",
      "4  (34.74865012400045, -92.27449074299966)   CLA10    TOP12       QUO25   \n",
      "\n",
      "   LocationId  BreakOutId BreakOutCategoryid ResponseId  \n",
      "0         5.0  AGE1844ALL              BOC16      RES23  \n",
      "1         5.0        BOC1               BOC1        NaN  \n",
      "2         5.0        BWT1               BOC1      RES24  \n",
      "3         5.0        BWT1               BOC1      RES41  \n",
      "4         5.0        BWT2               BOC1      RES24  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading CSV file\n",
    "file_path = \"C:/Users/CAU Student/Downloads/rows.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abdb8e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'Year', 'LocationAbbr', 'LocationDesc', 'Class', 'Topic', 'Question', 'DataSource', 'Response', 'Data_Value_Unit', 'Data_Value_Type', 'Data_Value', 'Data_Value_Footnote_Symbol', 'Data_Value_Footnote', 'Data_Value_Std_Err', 'Low_Confidence_Limit', 'High_Confidence_Limit', 'Sample_Size', 'Break_Out', 'Break_Out_Category', 'Geolocation', 'ClassId', 'TopicId', 'QuestionId', 'LocationId', 'BreakOutId', 'BreakOutCategoryid', 'ResponseId']\n"
     ]
    }
   ],
   "source": [
    "# Read in the first row of the CSV\n",
    "df = pd.read_csv('C:/Users/CAU Student/Downloads/rows.csv', nrows=0)\n",
    "\n",
    "# Get the column names\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71186670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required columns are present!\n"
     ]
    }
   ],
   "source": [
    "# Check if all required columns are present\n",
    "required_columns = [\n",
    "    'index', 'Year', 'LocationAbbr', 'LocationDesc', 'Class', 'Topic', 'Question', \n",
    "    'DataSource', 'Response', 'Data_Value_Unit', 'Data_Value_Type', 'Data_Value', \n",
    "    'Data_Value_Footnote_Symbol', 'Data_Value_Footnote', 'Data_Value_Std_Err', \n",
    "    'Low_Confidence_Limit', 'High_Confidence_Limit', 'Sample_Size', 'Break_Out',\n",
    "    'Break_Out_Category', 'Geolocation', 'ClassId', 'TopicId', 'QuestionId', 'LocationId', \n",
    "    'BreakOutId', 'BreakOutCategoryid', 'ResponseId'\n",
    "]\n",
    "\n",
    "missing_columns = [col for col in required_columns if col not in data.columns]\n",
    "\n",
    "if not missing_columns:\n",
    "    print(\"All required columns are present!\")\n",
    "else:\n",
    "    print(f\"Missing columns: {', '.join(missing_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2e0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [index, Year, LocationAbbr, LocationDesc, Class, Topic, Question, DataSource, Response, Data_Value_Unit, Data_Value_Type, Data_Value, Data_Value_Footnote_Symbol, Data_Value_Footnote, Data_Value_Std_Err, Low_Confidence_Limit, High_Confidence_Limit, Sample_Size, Break_Out, Break_Out_Category, Geolocation, ClassId, TopicId, QuestionId, LocationId, BreakOutId, BreakOutCategoryid, ResponseId]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "       index Year LocationAbbr LocationDesc Class Topic Question DataSource  \\\n",
      "count      0    0            0            0     0     0        0          0   \n",
      "unique     0    0            0            0     0     0        0          0   \n",
      "top      NaN  NaN          NaN          NaN   NaN   NaN      NaN        NaN   \n",
      "freq     NaN  NaN          NaN          NaN   NaN   NaN      NaN        NaN   \n",
      "\n",
      "       Response Data_Value_Unit  ... Break_Out Break_Out_Category Geolocation  \\\n",
      "count         0               0  ...         0                  0           0   \n",
      "unique        0               0  ...         0                  0           0   \n",
      "top         NaN             NaN  ...       NaN                NaN         NaN   \n",
      "freq        NaN             NaN  ...       NaN                NaN         NaN   \n",
      "\n",
      "       ClassId TopicId QuestionId LocationId BreakOutId BreakOutCategoryid  \\\n",
      "count        0       0          0          0          0                  0   \n",
      "unique       0       0          0          0          0                  0   \n",
      "top        NaN     NaN        NaN        NaN        NaN                NaN   \n",
      "freq       NaN     NaN        NaN        NaN        NaN                NaN   \n",
      "\n",
      "       ResponseId  \n",
      "count           0  \n",
      "unique          0  \n",
      "top           NaN  \n",
      "freq          NaN  \n",
      "\n",
      "[4 rows x 28 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 28 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   index                       0 non-null      object\n",
      " 1   Year                        0 non-null      object\n",
      " 2   LocationAbbr                0 non-null      object\n",
      " 3   LocationDesc                0 non-null      object\n",
      " 4   Class                       0 non-null      object\n",
      " 5   Topic                       0 non-null      object\n",
      " 6   Question                    0 non-null      object\n",
      " 7   DataSource                  0 non-null      object\n",
      " 8   Response                    0 non-null      object\n",
      " 9   Data_Value_Unit             0 non-null      object\n",
      " 10  Data_Value_Type             0 non-null      object\n",
      " 11  Data_Value                  0 non-null      object\n",
      " 12  Data_Value_Footnote_Symbol  0 non-null      object\n",
      " 13  Data_Value_Footnote         0 non-null      object\n",
      " 14  Data_Value_Std_Err          0 non-null      object\n",
      " 15  Low_Confidence_Limit        0 non-null      object\n",
      " 16  High_Confidence_Limit       0 non-null      object\n",
      " 17  Sample_Size                 0 non-null      object\n",
      " 18  Break_Out                   0 non-null      object\n",
      " 19  Break_Out_Category          0 non-null      object\n",
      " 20  Geolocation                 0 non-null      object\n",
      " 21  ClassId                     0 non-null      object\n",
      " 22  TopicId                     0 non-null      object\n",
      " 23  QuestionId                  0 non-null      object\n",
      " 24  LocationId                  0 non-null      object\n",
      " 25  BreakOutId                  0 non-null      object\n",
      " 26  BreakOutCategoryid          0 non-null      object\n",
      " 27  ResponseId                  0 non-null      object\n",
      "dtypes: object(28)\n",
      "memory usage: 0.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.describe())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a11b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the list of categorical columns\n",
    "categorical_columns = [\n",
    "    'LocationAbbr', 'Class', 'Topic', 'Question', 'DataSource', 'Response',\n",
    "    'Data_Value_Unit', 'Data_Value_Type', 'Break_Out', 'Break_Out_Category'\n",
    "]\n",
    "\n",
    "# 2. Handle missing values\n",
    "\n",
    "# For numerical columns\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# For categorical columns\n",
    "for column in categorical_columns:\n",
    "    if not df[column].mode().empty:\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[column].fillna(\"Missing\", inplace=True)  # replace with an appropriate placeholder value\n",
    "\n",
    "# 3. One-hot encode categorical columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "# 4. Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'index', 'LocationDesc', 'Data_Value_Footnote_Symbol',\n",
    "    'Data_Value_Footnote', 'Geolocation'\n",
    "]\n",
    "df_encoded.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# 5. Define X (features) and y (target)\n",
    "X = df_encoded.drop('Data_Value', axis=1)\n",
    "y = df_encoded['Data_Value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e78d936c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#splitting data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2420\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2417\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2419\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2420\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2098\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2095\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2098\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2099\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2102\u001b[0m     )\n\u001b[0;32m   2104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "#splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7882b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bdfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2af074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed98b04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41485c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ad5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e709f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce6f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b749281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f20df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f6bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd72a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28524c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203ae5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dda9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c6bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
